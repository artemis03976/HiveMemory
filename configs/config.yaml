# HiveMemory 主配置文件
#
# 配置分层原则:
# 1. 环境变量 (.env): 仅用于敏感信息 (API Keys)、基础设施地址 (Host/Port) 和环境切换 (Debug/Model)。
# 2. 此文件 (config.yaml): 用于定义所有业务逻辑参数、算法阈值、默认配置等。
#
# 环境变量覆盖机制:
# 尽管建议遵循上述分层，但所有配置项技术上都支持通过环境变量覆盖。
# 格式: HIVEMEMORY__<SECTION>__<FIELD> (双下划线分隔)
# 示例: HIVEMEMORY__PERCEPTION__SEMANTIC_FLOW__IDLE_TIMEOUT_SECONDS=900

# ========== 系统配置 ==========
system:
  name: "HiveMemory"
  version: "0.1.0"
  debug: true

# ========== 日志配置 ==========
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_path: null  # 设置为路径以启用文件日志
  console_output: true

# ========== LLM 模型配置 ==========
llm:
  gateway:
    provider: "litellm"
    model: "gpt-4o"
    api_key: null  # 通过环境变量 HIVEMEMORY__LLM__WORKER__API_KEY 设置
    api_base: null
    temperature: 0.7
    max_tokens: 4096

  librarian:
    provider: "litellm"
    model: "deepseek/deepseek-chat"
    api_key: null  # 通过环境变量 HIVEMEMORY__LLM__LIBRARIAN__API_KEY 设置
    api_base: null
    temperature: 0.3
    max_tokens: 4096

# ========== Embedding 模型配置 ==========
embedding:
  default:
    model_name: "BAAI/bge-m3"
    device: "cpu"  # 可选: cpu, cuda, mps
    cache_dir: null
    batch_size: 32
    normalize_embeddings: true
    dimension: 1024

  perception:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cpu"
    cache_dir: null
    batch_size: 32
    normalize_embeddings: true
    dimension: 384

# ========== 向量数据库配置 ==========
qdrant:
  host: "localhost"
  port: 6333
  grpc_port: 6334
  api_key: null  # 通过环境变量 HIVEMEMORY__QDRANT__API_KEY 设置
  collection_name: "hivememory_main"
  vector_dimension: 1024
  distance_metric: "Cosine"
  on_disk_payload: false

# ========== Redis 配置 ==========
redis:
  host: "localhost"
  port: 6379
  password: null  # 通过环境变量 HIVEMEMORY__REDIS__PASSWORD 设置
  db: 0
  decode_responses: true

# ========== 感知层配置 ==========
perception:
  layer_type: "semantic_flow"  # 可选: semantic_flow, simple
  enable: true

  semantic_flow:
    idle_timeout_seconds: 900  # 15分钟
    scan_interval_seconds: 30
    semantic_threshold: 0.6
    short_text_threshold: 50
    ema_alpha: 0.3
    max_processing_tokens: 8192
    enable_smart_summary: false

  simple:
    message_threshold: 6
    timeout_seconds: 900
    enable_semantic_trigger: true

# ========== 记忆生成配置 ==========
generation:
  extractor:
    max_retries: 2
    temperature: null  # null 则使用 LLM 默认值
    max_tokens: null
    system_prompt: null
    user_prompt: null
    llm_config: null  # 使用全局 librarian 配置

  deduplicator:
    high_similarity_threshold: 0.95  # TOUCH/UPDATE 分界
    low_similarity_threshold: 0.75   # UPDATE/CREATE 分界
    content_similarity_threshold: 0.9
    enable_vitality_tracking: true

# ========== 记忆检索配置 ==========
retrieval:
  enable_routing: true

  router:
    router_type: "simple"  # simple/llm/always/never
    min_query_length: 3
    min_keyword_count: 1
    additional_keywords: []
    llm_config: null
    system_prompt: null

  processor:
    enable_time_parsing: true
    enable_type_detection: true
    enable_query_expansion: true
    expansion_keywords: []
    enable_llm_rewrite: false
    llm_config: null

  renderer:
    type: "full"  # 可选: full, cascade, compact
    render_format: "xml"  # xml/markdown
    max_tokens: 2000
    max_content_length: 500
    show_artifacts: false
    stale_days: 90

  retriever:
    top_k: 5
    score_threshold: 0.75
    enable_hybrid_search: true
    enable_parallel: true

    dense:
      enabled: true
      top_k: 50
      score_threshold: 0.0
      enable_time_decay: true
      time_decay_days: 30
      enable_confidence_boost: true

    sparse:
      enabled: true
      top_k: 50
      score_threshold: 0.0

    fusion:
      rrf_k: 60
      dense_weight: 1.0
      sparse_weight: 1.0
      final_top_k: 5

    reranker:
      enabled: true
      type: "cross_encoder"  # noop 或 cross_encoder
      model_name: "BAAI/bge-reranker-v2-m3"
      device: "cpu"
      use_fp16: true
      batch_size: 32
      top_k: 20
      normalize_scores: true

# ========== 记忆生命周期配置 ==========
lifecycle:
  vitality_calculator:
    code_snippet_weight: 1.0
    fact_weight: 0.9
    url_resource_weight: 0.8
    reflection_weight: 0.7
    user_profile_weight: 0.6
    work_in_progress_weight: 0.5
    default_weight: 0.5
    max_access_boost: 20.0
    points_per_access: 2.0
    decay_lambda: 0.01

  reinforcement_engine:
    enable_event_history: true
    event_history_limit: 10000
    hit_boost: 5.0
    citation_boost: 20.0
    positive_feedback_boost: 50.0
    negative_feedback_penalty: -50.0
    negative_confidence_multiplier: 0.5

  archiver:
    archive_dir: "data/archived"
    compression: true

  garbage_collector:
    low_watermark: 20.0
    batch_size: 10
    enable_schedule: false
    interval_hours: 24

  high_watermark: 80.0
